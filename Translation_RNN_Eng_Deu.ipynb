{"cells":[{"cell_type":"markdown","metadata":{"id":"RMS8xatF1UG7"},"source":["# Import Necessary Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3083,"status":"ok","timestamp":1715191086346,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"_L1qlR35ciFx"},"outputs":[],"source":["# Preprocessing\n","from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import re\n","import random\n","\n","# Torch\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","# Numpy + Matrix Operations\n","import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","\n","# GPU Access\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"jHJbOlVr1fU3"},"source":["# Mount Google Drive\n","----------------------------------------------------\n","Mount Drive to access dataset.\n","\n","**Dataset** - Many Things (English - German)\n","\n","**URL** - https://www.manythings.org/anki/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22226,"status":"ok","timestamp":1715191108570,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"1lssrpotcpYJ","outputId":"a7988c17-7a59-4499-9d5c-c34709a185e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"WBJ778JS1uVt"},"source":["\n","# Preprocessing\n","----------------------------------------------------\n","There are two main objectives of the preproccessing.\n","----------------------------------------------------\n","\n","**1: Language Encoding**\n","---\n","Encode the language using one-hot vectors [ 0, 0, 0, 1, 0, ... ,0 ] to      access each unique word in the language by using a word-to-index dictionary. Additionally we will track the unique word count as well as each word's frequency.\n","\n","**2: File Text Processing**\n","---\n","We will split the file by the tabulation character '\\t' to seperate the English, German and CC. We will then use regex to eliminate the CC tags and created a nested list of Enlgish and German sentence pairs.\n","\n","ex. [ [English Sentence, German Sentence], ... ]"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1715191108570,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"gfpqXr8jcsHE"},"outputs":[],"source":["SOS_Token = 0\n","EOS_Token = 1\n","\n","class Language:\n","  def __init__(self, name):\n","    self.name = name # language\n","    self.word_to_idx = {} # word to index mapping\n","    self.idx_to_word = {0: \"SOS\", 1: \"EOS\"} # index to word mapping\n","    self.word_freq = {} # word to frequency mapping\n","    self.word_count = 2 # unique word count\n","\n","  def add_sentence(self, sentence):\n","    for word in sentence.split(' '): # for each word (split by whitespace)\n","      self.add_word(word) # use add word method\n","\n","  def add_word(self, word):\n","    # New Word\n","    if word not in self.word_to_idx:\n","      self.word_to_idx[word] = self.word_count # add word as key -> count\n","      self.idx_to_word[self.word_count] = word # add count as key -> word\n","      self.word_freq[word] = 1 # initialize frequency\n","      self.word_count += 1 # increment unique word count\n","    # Repeated Word\n","    else:\n","      self.word_freq[word] += 1 # increment word frequency"]},{"cell_type":"markdown","metadata":{"id":"s4ocF9fi12YG"},"source":["**Unicode to ASCII**\n","---\n","Since these databases are multilingual there are in unicode not ASCII so using these methods to convert."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1715191108570,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"qfA9hLQ8ctka"},"outputs":[],"source":["def unicode_to_ASCII(string):\n","  return ''.join(\n","      c for c in unicodedata.normalize('NFD', string) # normalize Unicode chars\n","      if unicodedata.category(c) != 'Mn' # cut non spacing marks\n","  )\n","\n","def clean_string(string):\n","  string = string.lower().strip() # lowercase and get rid of excess whitespace\n","  string = unicode_to_ASCII(string) # convert Unicode to ASCII\n","  string = re.sub(r\"([.!?])\", r\" \\1\", string) # insert space before punctuation\n","  string = re.sub(r\"[^a-zA-Z!?]+\", r\" \", string) # remove non alphabetic chars\n","\n","  return string.strip()\n","\n","def remove_punc(pairs):\n","  punctuation_pattern = r'[^\\w\\s]' # regex punctuation patterns\n","  cleaned_list = []\n","\n","  # Remove punctuation from pairs\n","  for sublist in pairs:\n","    cleaned_sublist = [re.sub(punctuation_pattern, '', word) for word in sublist]\n","    cleaned_list.append(cleaned_sublist)\n","\n","  return cleaned_list"]},{"cell_type":"markdown","metadata":{"id":"hxATBzTh14y5"},"source":["**Reading The File**\n","---\n","Need to strip the CC tags from the file and split English and German sentences into pairs."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1715191108570,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"TNHTrlm1cv4a"},"outputs":[],"source":["def read_file_langs(lang_1, lang_2, switch=False):\n","  print(\"Reading file...\")\n","  # Strip whitespace and spit into lines\n","\n","  # File Options: Full set, Test set respectively\n","  lines = open('/content/drive/My Drive/Translation-RNN/deu.txt',\n","               encoding='utf-8').read().strip().split('\\n')\n","  # lines = open('/content/drive/My Drive/Translation-RNN/deu_test_set.txt',\n","  #              encoding='utf-8').read().strip().split('\\n')\n","\n","  # Remove the CC tag from each line\n","  clean_lines = []\n","  for line in lines:\n","    clean_lines.append(remove_CC(line))\n","\n","  # Split the lines into English German pairs\n","  split_lines = []\n","  for line in clean_lines:\n","    split_lines.append(line.split('\\t'))\n","\n","  sentence_pairs = remove_punc(split_lines)\n","\n","  # Switch case: allows for reverse translation\n","  if not switch:\n","    native_lang = Language(lang_1)\n","    output_lang = Language(lang_2)\n","  else:\n","    sentence_pairs = [list(reversed(pair)) for pair in sentence_pairs]\n","    native_lang = Language(lang_1)\n","    output_lang = Language(lang_2)\n","\n","  return native_lang, output_lang, sentence_pairs\n","\n","# This accounts for the 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272\n","# (CM) & #8597805 (Roujin)' found in the dataset\n","def remove_control_characters(text):\n","    # Remove control characters from the text using regular expression\n","    cleaned_text = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', text)\n","    return cleaned_text"]},{"cell_type":"markdown","metadata":{"id":"mHn8_nhT2LQ1"},"source":["**Training Data Streamlining**\n","---\n","Going to break sentences down to 12 word maximum and account for words like I'm using a simple dictionary with the most common contractions."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1715191108570,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"0zCcSpQVcyZe"},"outputs":[],"source":["# Max Sentence Length\n","SENTENCE_LENGTH = 12\n"]},{"cell_type":"markdown","metadata":{"id":"krITidvg4BbO"},"source":["Remove CC\n","---\n","> This particular dataset has a third field in each line that needs to be removed prior to generating the pairs.\n","\n","> Format...\n","\n","> Go.\tGeh.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1715191108570,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"QegStLg7c0g6"},"outputs":[],"source":["def remove_CC(line):\n","  cleaned_line = re.sub(r'^(.*?)\\t(.*?)\\t.*$', r'\\1\\t\\2', line)\n","\n","  return cleaned_line"]},{"cell_type":"markdown","metadata":{"id":"Zp3aOghw2OqD"},"source":["**Full Preprocessing**\n","---\n","> Put everything together"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7190,"status":"ok","timestamp":1715191115745,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"R6r6fkK_c2QC","outputId":"cd5a59a4-185e-4b48-b051-3c661d5ff7c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading file...\n","Read 271774 sentence pairs\n","Trimmed to 271774 pairs of 12 words long (max)\n","Counted words:\n","eng 20195\n","ger 42452\n","['Tom is a coward', 'Tom ist ein Feigling']\n"]}],"source":["def preprocess_data(lang_1, lang_2, switch=False):\n","  native_lang, output_lang, pairs = read_file_langs(lang_1, lang_2, switch)\n","  print(f'Read {len(pairs)} sentence pairs')\n","  print(f'Trimmed to {len(pairs)} pairs of {SENTENCE_LENGTH} words long (max)')\n","  # Add each sentence to the language\n","  for pair in pairs:\n","    native_lang.add_sentence(pair[0])\n","    output_lang.add_sentence(pair[1])\n","  # Print word counts for reference\n","  print(\"Counted words:\")\n","  print(native_lang.name, native_lang.word_count)\n","  print(output_lang.name, output_lang.word_count)\n","\n","  return native_lang, output_lang, pairs\n","\n","native_lang, output_lang, pairs = preprocess_data('eng', 'ger', False)\n","print(random.choice(pairs))\n"]},{"cell_type":"markdown","metadata":{"id":"RUY-q4_f2UkJ"},"source":["#Encoder\n","---\n","The Encoder Decoder Network is a crucial architecture for language translation. This is because just looking at each input and producing an output (ex. word by word) doesn't capture the nuance of translation. Some sentence pairs have different lengths or have different structure based on how verbs are used.\n","\n","Example\n","\n","**ENG:** Did Tom mind?\n","**GER:** Hatte Tom etwas einzuwenden?\n","\n","The function of the encoder is to take the input and generate a context vector to generate the hidden state that will be used by the decoder. The dropout parametr will allow us to limit the model's dependency on certain words. This will randomly drop part of the input to force the model to learn more nuanced patterns for translation. It is important to note that dropout should not be too large to esnure the model retains proper accuracy.\n","\n","This video was helpful in understanding the encoder functionality.\n","\n","**link**: https://youtu.be/jCrgzJlxTKg?si=pDccqewYrWZzFOas\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1715191115745,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"3gOPJeYrc4EO"},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","  # Initialize as subclass of nn.Module\n","  def __init__(self, input_size, hidden_size, pr_dropout = 0.1):\n","    super(EncoderRNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    # Initialize Encoder Layers\n","    self.embedding = nn.Embedding(input_size, hidden_size) # embedded\n","    self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True) # GRU\n","    self.dropout = nn.Dropout(pr_dropout) # dropout\n","\n","  def forward(self, input):\n","    # Create embedded layer and perform dropout\n","    embedded = self.embedding(input)\n","    embedded_dropout = self.dropout(embedded)\n","    # Pass into GRU and return output and hidden state\n","    output, hidden_state = self.gru(embedded_dropout)\n","\n","    return output, hidden_state"]},{"cell_type":"markdown","metadata":{"id":"U1JbrRji2We1"},"source":["#Decoder\n","---\n","The Encoder Decoder Network is a crucial architecture for language translation. This is because just looking at each input and producing an output (ex. word by word) doesn't capture the nuance of translation. Some sentence pairs have different lengths or have different structure based on how verbs are used.\n","\n","Example\n","\n","**ENG:** Did Tom mind?\n","**GER:** Hatte Tom etwas einzuwenden?\n","\n","The decoder takes the previous hidden state as well as the input and feeds these into the GRU (with the assistance of activation and normalization functions) to generate the output sequence in addition to an updated hidden state that will be used in the next forward step.\n","\n","The YouTube channel that I used for the encoder has a good illustration of the decoder as well."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"cP0iUFvnc8s4"},"outputs":[],"source":["class DecoderRNN(nn.Module):\n","  # Initialize as subclass of nn.Module\n","  def __init__(self, hidden_size, output_size):\n","    super(DecoderRNN, self).__init__()\n","    # Initialize Decoder Layers\n","    self.embedding = nn.Embedding(output_size, hidden_size)\n","    self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True)\n","    self.out = nn.Linear(hidden_size, output_size)\n","\n","  def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n","    # Encoder Outputs: (batch_size, sequence_length, hidden_size)\n","    batch_size = encoder_outputs.size(0)\n","    # Create input vector of SOS tokens\n","    decoder_in = torch.empty(batch_size, 1, dtype = torch.long, device = device).fill_(SOS_Token)\n","    # Transfer hidden state\n","    decoder_hidden = encoder_hidden\n","    decoder_out = []\n","    # Step through sentence and append decoder outputs\n","    for idx in range(SENTENCE_LENGTH):\n","      decoder_output, decoder_hidden  = self.forward_step(decoder_in, decoder_hidden)\n","      decoder_out.append(decoder_output)\n","      # Teacher forcing\n","      if target_tensor is not None:\n","        decoder_in = target_tensor[:, idx].unsqueeze(1)\n","      # Use decoder output for new decoder input\n","      else:\n","        best_out = (decoder_output.topk(1))[1] # best predicted output\n","        decoder_in = best_out.squeeze(-1).detach() # feed into input\n","    # Concat decoder outputs and apply softmax\n","    decoder_out = torch.cat(decoder_out, dim = 1) # sequence dim\n","    norm_decoder_out = F.log_softmax(decoder_out, dim = -1)\n","\n","    return norm_decoder_out, decoder_hidden, None\n","\n","  # Each substep of a forward pass\n","  def forward_step(self, input, hidden):\n","    output = self.embedding(input) # embed input\n","    output = F.relu(output) # activation function\n","    output, hidden_state = self.gru(output, hidden) # feed into GRU\n","    output = self.out(output) # get decoder output\n","\n","    return output, hidden_state"]},{"cell_type":"markdown","metadata":{"id":"v6_GJJqa2a2f"},"source":["#Attention\n","---\n","We are using Luong Attention. Luong Attention and Bahdanau Attention are the most common with the main difference being that Luong uses the current and past hidden states whareas Bahdnau only uses the past hidden state. Below is a link for a more in depth comparison of the two.\n","\n","**Link** - https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention\n","\n","A very brief description of attention is that it is a method that essentially allows the model to focus on certain parts of the sequence. This is acheived by calculating attention weights and applying them to the encoder output."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"UILE8VW-Ab6y"},"outputs":[],"source":["class LuongAttention(nn.Module):\n","  # Initialize as subclass of nn.Module\n","  def __init__(self, hidden_size):\n","    super(LuongAttention, self).__init__()\n","    self.Wa = nn.Linear(hidden_size, hidden_size)\n","\n","  # Q = Query, K = Keys\n","  def forward(self, Q, K):\n","    Q_transformed = self.Wa(Q)\n","\n","    # Test to verify size\n","    # print(\"Q size:\", Q_transformed.size())\n","    # print(\"K size:\", K.T.size())\n","\n","    # Last dim is seq length\n","    attn_scores = torch.matmul(Q, K.transpose(1, 2))\n","    attn_weights = F.softmax(attn_scores, dim = -1)\n","    # Batch matric mult\n","    context = torch.bmm(attn_weights, K)\n","\n","    return context, attn_weights"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"re_VYA17dB6G"},"outputs":[],"source":["class AttnDecoderRNN(nn.Module):\n","  # Initialize as subclass of nn.Module\n","  def __init__(self, hidden_size, output_size, pr_dropout = 0.1):\n","    super(AttnDecoderRNN, self).__init__()\n","    self.embedding = nn.Embedding(output_size, hidden_size) #embedded layer\n","    # self.attention = BahdanauAttention(hidden_size)\n","    self.attention = LuongAttention(hidden_size) # attn mechanism\n","    self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first = True) # GRU\n","    self.out = nn.Linear(hidden_size, output_size) # output layer\n","    self.dropout = nn.Dropout(pr_dropout) # perform dropout\n","\n","  def forward(self, encoder_outputs, encoder_hidden, target_tensor = None):\n","    batch_size = encoder_outputs.size(0) # get batch size\n","    # Input vector of SOS tokens\n","    decoder_input = torch.empty(batch_size, 1, dtype=torch.long,\n","                                device = device).fill_(SOS_Token)\n","    # Pass (t - 1) hidden into (t) hidden\n","    decoder_hidden = encoder_hidden\n","    decoder_out, attentions = [], []\n","\n","    # Step through sentence and append decoder outputs\n","    for i in range(SENTENCE_LENGTH):\n","      # Perform forward step\n","      decoder_output, decoder_hidden, attn_weights = self.forward_step(\n","          decoder_input, decoder_hidden, encoder_outputs)\n","\n","      decoder_out.append(decoder_output) # append dec output for idx\n","      attentions.append(attn_weights) # append attn_weights fro idx\n","\n","      # Teacher forcing\n","      if target_tensor is not None:\n","        decoder_input = target_tensor[:, i].unsqueeze(1)\n","      # Use decoder output for new decoder input\n","      else:\n","        best_out = (decoder_output.topk(1))[1]\n","        decoder_input = best_out.squeeze(-1).detach()\n","\n","    # Concat outputs along 2nd dim\n","    decoder_out = torch.cat(decoder_out, dim = 1)\n","    # Apply softmax (normalize)\n","    norm_decoder_out = F.log_softmax(decoder_out, dim = -1)\n","    # Concat attention weights along 2nd dim\n","    attentions = torch.cat(attentions, dim = 1)\n","\n","    return norm_decoder_out, decoder_hidden, attentions\n","\n","    # Each substep of a forward pass\n","  def forward_step(self, input, hidden, encoder_outputs):\n","    # Create embedded and perform dropout\n","    embedded = self.embedding(input)\n","    dropout_embedded = self.dropout(embedded)\n","    # Obtain context vec and attn_weights\n","    Q = hidden.permute(1, 0, 2)\n","    context, attn_weights = self.attention(Q, encoder_outputs)\n","    # Concat context to input for GRU input\n","    gru_in = torch.cat((embedded, context), dim = 2)\n","    # Run through GRU and output layer (linear)\n","    output, hidden = self.gru(gru_in, hidden)\n","    output = self.out(output)\n","\n","    return output, hidden, attn_weights"]},{"cell_type":"markdown","metadata":{"id":"SBAec1l42f9B"},"source":["#Training Setup\n","---\n","Here we are essesntially just obtaining the indices for the input and target words using the structures defined in the preproccessing portion.\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"-Bo7npNXdClu"},"outputs":[],"source":["# Get words' corresponding indices\n","def indexesFromSentence(lang, sentence):\n","  idcs = []\n","  for word in sentence.split(' '):\n","    idcs.append(lang.word_to_idx[word])\n","\n","  return idcs\n","\n","# Create tensor from indices\n","def tensorFromSentence(lang, sentence):\n","  idcs = indexesFromSentence(lang, sentence)\n","  idcs.append(EOS_Token) # append EOS\n","  # Infer number of columns (since sentence size is variable)\n","  tens = torch.tensor(idcs, dtype = torch.long, device = device).view(1, -1)\n","\n","  return tens\n","\n","# Create tensor pair from sentence pair\n","def tensorsFromPair(pair):\n","  input_tensor = tensorFromSentence(input_lang, pair[0])\n","  target_tensor = tensorFromSentence(output_lang, pair[1])\n","\n","  return (input_tensor, target_tensor)\n","\n","def get_dataloader(batch_size):\n","  # Preproccess\n","  input_lang, output_lang, pairs = preprocess_data('English', 'German', False)\n","  # Initialize word indices\n","  n = len(pairs)\n","  input_ids = np.zeros((n, SENTENCE_LENGTH), dtype=np.int32)\n","  target_ids = np.zeros((n, SENTENCE_LENGTH), dtype=np.int32)\n","  # Create word indices\n","  for idx, (inp, tgt) in enumerate(pairs):\n","    inp_ids = indexesFromSentence(input_lang, inp)[:SENTENCE_LENGTH - 1]\n","    tgt_ids = indexesFromSentence(output_lang, tgt)[:SENTENCE_LENGTH - 1]\n","    inp_ids.append(EOS_Token) # append EOS token\n","    tgt_ids.append(EOS_Token) # append EOS token\n","    input_ids[idx, :len(inp_ids)] = inp_ids\n","    target_ids[idx, :len(tgt_ids)] = tgt_ids\n","  # Create training data\n","  training_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n","                               torch.LongTensor(target_ids).to(device))\n","  train_sampler = RandomSampler(training_data) # sample data randomly\n","  train_dataloader = DataLoader(training_data,\n","                                sampler = train_sampler,\n","                                batch_size = batch_size)\n","\n","  return input_lang, output_lang, train_dataloader"]},{"cell_type":"markdown","metadata":{"id":"W9wdHmC6NzGZ"},"source":["#Training\n","---\n","Now we continually feed snetence pairs to the model from the dataset. The time function simply aids with visualizing the progress of the model. It's important to note that out dataset is very large and you do not necessarily need to complete the entirety of the training to generate an accurate model. Additionally, you cn adjust the number of epochs/size of the dataset based on the accuracy you desire. Using the GPU is almost necessary for this step or the training could take hours.\n","\n","You can play aorund with certain (non learnable) model paramaters such as dropout rate. Or you can altogether use a different model architecture (such as LSTM)."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"U4SwSZ4qdEbt"},"outputs":[],"source":["def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n","          decoder_optimizer, criterion):\n","  total_loss = 0\n","  # Iterate over batches\n","  for data in dataloader:\n","    input_tensor, target_tensor = data\n","    # Zero gradients\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    # Pass through encoder and decoder\n","    encoder_outputs, encoder_hidden = encoder(input_tensor)\n","    decoder_outputs = decoder(encoder_outputs, encoder_hidden, target_tensor)[0]\n","    loss = criterion(\n","      decoder_outputs.view(-1, decoder_outputs.size(-1)),\n","      target_tensor.view(-1)\n","    )\n","    loss.backward()\n","    # Optimize the gradients\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","    # Accumulate loss\n","    total_loss += loss.item()\n","\n","  return total_loss / len(dataloader)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"QoNo1OyFdHW6"},"outputs":[],"source":["import time\n","import math\n","\n","def asMinutes(s):\n","  m = math.floor(s / 60)\n","  s -= m * 60\n","\n","  return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","  now = time.time()\n","  s = now - since\n","  es = s / (percent)\n","  rs = es - s\n","\n","  return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"6KpMtKcxdJic"},"outputs":[],"source":["def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n","               print_every=25, plot_every=100):\n","  start = time.time()\n","  plot_losses = []\n","  print_loss_total = 0\n","  plot_loss_total = 0\n","  # Initialize stochastic optimizer\n","  encoder_optimizer = optim.Adam(encoder.parameters(), lr = learning_rate)\n","  decoder_optimizer = optim.Adam(decoder.parameters(), lr = learning_rate)\n","  criterion = nn.NLLLoss()\n","  # Iterate over epochs\n","  for epoch in range(1, n_epochs + 1):\n","    loss = train_epoch(train_dataloader, encoder, decoder,\n","                       encoder_optimizer, decoder_optimizer, criterion)\n","    print_loss_total += loss\n","    plot_loss_total += loss\n","    # Print and plot loss over designated interval\n","    if epoch % print_every == 0:\n","      print_loss_avg = print_loss_total / print_every\n","      print_loss_total = 0\n","      print('%s (%d %d%%) %.3f' % (timeSince(start, epoch / n_epochs),\n","                                    epoch, epoch / n_epochs * 100, print_loss_avg))\n","    if epoch % plot_every == 0:\n","      plot_loss_avg = plot_loss_total / plot_every\n","      plot_losses.append(plot_loss_avg)\n","      plot_loss_total = 0\n","\n","  showPlot(plot_losses)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"jyWWJuspdLW-"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","# Plot the loss over the epochs\n","def showPlot(points):\n","  plt.figure()\n","  fig, ax = plt.subplots()\n","  loc = ticker.MultipleLocator(base=0.2)\n","  ax.yaxis.set_major_locator(loc)\n","  plt.plot(points)"]},{"cell_type":"markdown","metadata":{"id":"lqlvgjG72oZ4"},"source":["#Evaluation\n","---\n","Essentially the training process but without the use of target vectors (basically the model has no feedback assistance now)."]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"FZxf4kAUdNta"},"outputs":[],"source":["def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n","  with torch.no_grad():\n","    input_tensor = tensorFromSentence(input_lang, sentence)\n","    # Pass through encoder and decoder\n","    encoder_outputs, encoder_hidden = encoder(input_tensor)\n","    decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n","    # Get best k\n","    topi = decoder_outputs.topk(1)[1]\n","    decoded_ids = topi.squeeze()\n","    # Append word and EOS token from indices\n","    decoded_words = []\n","    for idx in decoded_ids:\n","      if idx.item() == EOS_Token:\n","        decoded_words.append('<EOS>')\n","        break # break out when hit end of sentence\n","      decoded_words.append(output_lang.idx_to_word[idx.item()])\n","  return decoded_words, decoder_attn"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715191115746,"user":{"displayName":"Adam","userId":"14366619704249455850"},"user_tz":240},"id":"KVzyKvCIdP_g"},"outputs":[],"source":["def evaluateRandomly(encoder, decoder, n = 10):\n","  # Evaluate the batches randomly\n","  for i in range(n):\n","    pair = random.choice(pairs)\n","    print('Input sequence:', pair[0])\n","    print('Correct translation:', pair[1])\n","    output_words = evaluate(encoder, decoder, pair[0], input_lang, output_lang)[0]\n","    output_sentence = ' '.join(output_words)\n","    print('Generated translation', output_sentence)\n","    print('')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f51fIFrndRMh","executionInfo":{"status":"ok","timestamp":1715193036594,"user_tz":240,"elapsed":134599,"user":{"displayName":"Adam","userId":"14366619704249455850"}},"outputId":"a4335eb6-5cf1-418d-95b9-5674eef79d5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading file...\n","Read 271774 sentence pairs\n","Trimmed to 271774 pairs of 12 words long (max)\n","Counted words:\n","English 20195\n","German 42452\n","Training on: cuda\n","3m 12s (- 28m 51s) (1 10%) 2.392\n","6m 23s (- 25m 33s) (2 20%) 1.653\n","9m 34s (- 22m 19s) (3 30%) 1.391\n","12m 44s (- 19m 7s) (4 40%) 1.235\n","15m 56s (- 15m 56s) (5 50%) 1.130\n","19m 7s (- 12m 44s) (6 60%) 1.049\n","22m 17s (- 9m 33s) (7 70%) 0.986\n","25m 28s (- 6m 22s) (8 80%) 0.934\n","28m 40s (- 3m 11s) (9 90%) 0.890\n","31m 50s (- 0m 0s) (10 100%) 0.852\n"]}],"source":["import torchvision\n","import torchaudio\n","# Set hidden size and batch size\n","hidden_size = 128\n","batch_size = 32\n","# Use GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Load data\n","input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n","# Initialize encoder and decoder\n","encoder = EncoderRNN(input_lang.word_count, hidden_size).to(device)\n","decoder = AttnDecoderRNN(hidden_size, output_lang.word_count).to(device)\n","# To ensure we are training on GPU\n","print(\"Training on:\", device)\n","# Train\n","train(train_dataloader, encoder, decoder, 10, print_every = 1, plot_every = 1)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"ObGKBQwSdTEC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715193036796,"user_tz":240,"elapsed":205,"user":{"displayName":"Adam","userId":"14366619704249455850"}},"outputId":"44ee4f07-e06c-456b-995b-737b597a908b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input sequence: Tom mustve thought Mary didnt need to do that\n","Correct translation: Tom hat bestimmt gedacht Maria müsse das nicht machen\n","Generated translation Tom hat Maria gesagt dass er das nicht tun müsse <EOS>\n","\n","Input sequence: When did you last hear from Tom\n","Correct translation: Wann haben Sie das letzte Mal etwas von Tom gehört\n","Generated translation Wann hast du gestern von Tom gehört <EOS>\n","\n","Input sequence: Tom is in the other room unpacking boxes\n","Correct translation: Tom ist im Zimmer nebenan und packt Kisten aus\n","Generated translation Tom ist in der Zimmer nur halb drei Kisten <EOS>\n","\n","Input sequence: He knows how to milk a cow\n","Correct translation: Er weiß wie man eine Kuh melkt\n","Generated translation Er weiß wie man einen kleinen Fehler macht <EOS>\n","\n","Input sequence: Stand up\n","Correct translation: Stehen Sie auf\n","Generated translation Steht auf links auf deinen Bett <EOS>\n","\n","Input sequence: He was stunned by her beauty\n","Correct translation: Er war überwältigt von ihrer Schönheit\n","Generated translation Er wurde von ihrer Schönheit Schönheit von ihrer Schönheit unterhalten <EOS>\n","\n","Input sequence: I knew Tom would do something stupid\n","Correct translation: Ich wusste dass Tom etwas Dummes machen würde\n","Generated translation Ich wusste dass Tom etwas Dummes würde machen würde <EOS>\n","\n","Input sequence: Tom had no idea how tired Mary was\n","Correct translation: Tom hatte keine Ahnung wie erschöpft Mary war\n","Generated translation Tom hatte keine Ahnung wie lange Maria war <EOS>\n","\n","Input sequence: Where is your homework\n","Correct translation: Wo sind deine Hausaufgaben\n","Generated translation Wo ist deine Hausaufgaben in deine Hausaufgaben <EOS>\n","\n","Input sequence: My bike has been stolen\n","Correct translation: Mein Rad wurde gestohlen\n","Generated translation Mein Fahrrad wurde gestohlen zu haben <EOS>\n","\n"]}],"source":["encoder.eval()\n","decoder.eval()\n","evaluateRandomly(encoder, decoder)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"authorship_tag":"ABX9TyM3vpKlYhNLhnc/n5VsruZ/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}